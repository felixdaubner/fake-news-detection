{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Fake News Detection\n",
    "\n",
    "By Felix Daubner - Hochschule der Medien\n",
    "\n",
    "Module 'Supervised and Unsupervised Learning' - Prof. Dr.-Ing. Johannes Maucher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section should summarize the previous notebooks focusing on the findings, challenges, learnings and, of course, hypothesis which were stated at the beginning of the project in [problem understanding](01_problem-understanding.ipynb).\n",
    "\n",
    "In summary, it can be said that a machine learning model for dealing with fake news detection was successfully implemented, trained and evaluated. On this journey, there were some hurdles and challenges as well as possible improvements that can be implemented in the future.\n",
    "\n",
    "The data for the fake-news classification was quite large but could even have been expanded. However, in the context of this project, a larger data set was dispensed with in the interests of feasibility. In principle, larger data sets should be prefered. The data was scraped from [POLITIFACT.com](https://www.politifact.com/) in [data access](02_data-access.ipynb). Due to the simple structure of [POLITIFACT.com](https://www.politifact.com/)s website, the scraping process did not face many challenges. All the wanted data was scraped in the expected way and able to use it for training the fake-news model.\n",
    "\n",
    "The findings in [data understanding](03_data-understanding.ipynb) could have been used further. For e.g. the model could have been significantly improved by the findings based on the political orientations of individuals. Unfortunately, the political orientation of each person was not provided by [POLITIFACT.com](https://www.politifact.com/). Also, 'issue' could have relevant for the model too. Those questions should be answered in projects that claim to be complete. Due to time restrictions, some trade-offs must have been made.\n",
    "One hypothesis stated in [problem understanding](01_problem-understanding.ipynb) could already been answered based on the insights in [data understanding](03_data-understanding.ipynb). The share of fake-news on Social Media is higher than any other channel. Especially Facebook and Twitter/X as the most common platforms for text-based fake-news stood out. Conventional channels like interviews, debates or ads did not have such a large share of fake-news. This underlines the relevance of current discussions on freedom of speech in relation to social media. Particularly in the USA, where Donald Trump, a supporter of freedom of speech, has been appointed president, fake-news are more present than ever before due to the non-regulation of content on social media such as X and probably soon also Facebook.\n",
    "Coming back to [data understanding](03_data-understanding.ipynb), some further insights into the word clouds could also have contributed to get a better understanding of the models decision to classify statements as true or false. This point is particularly necessary when transparency and explainability of the model are a higher priority.\n",
    "\n",
    "Preparing the data was driven by decisions based on insights from [data understanding](03_data-understanding.ipynb). The data was also prepared by tokenizing and padding the text sequences. Also, finetuning the tokenizer or even using a pre-trained tokenizer could have improved the models performance. Overall, [data preprocessing](04_data-preprocessing.ipynb) went quite smoothly, not facing many challenges. Preprocessing of the test data (LIAR.csv) using only the insights available gained from the training data could have been implemented successfully. To futher automate the process, a pipeline should be implemented which will automatically transform the data into the required structure.\n",
    "\n",
    "The baseline model was trained to have a performance reference. It was communicated in [baseline](05_baseline.ipynb) that a Logistic Regression model might not be useful when trying to classify statements. Still, the performance was sufficient to act as a simple baseline model.\n",
    "\n",
    "The biggest challenge of this project was [model training](06_model-training.ipynb). Before designing different types of machine learning models, the data had to be prepared. As the data consists of both, tokenized text data and encoded cateogorical columns, two inputs were needed if the model was to be trained on both kinds of data. Fortunately, the input layers had to be implemented once and were able to be used for every model.\n",
    "The approach to design the models architecture was rather oriented on having around the same number of trainable parameters. This led to sometimes a more complex model. This approach was implemented to make the different types of models comparable. Also, the same hyperparameters have been used for training the different models. This was also required to compare the performance of all models to each other and finally chose the best one.\n",
    "The model which was finally chosen as the 'final model' was a model of type LSTM. Although a Feedforward Neural Network achieved better results on the training and validation, the decision was also made based on the ability of LSTM to handle and process sequential data. By optimizing hyperparameters in a pre-defined scope, the initally trained LSTM was further optimized. Hyperparametertuning and feature extraction were only handled in a short manner, also due to time and feasibility restrictions. To optimize the model, its architecture and hyperparamters are more structured and detailed approach has to be taken next time. \n",
    "The final model still managed to achieve extraordinary results on the training data which indicates clear signs of overfitting. The performance on the test data (LIAR.csv) did not reach the same levels. The model probably needs to be trained on more data to not overfit. Also, the architecture of the model might be too complex.\n",
    "\n",
    "At the end, a thematic digression was made by classifying the sentiment of each statement using a pre-trained open-sourced model. The model was able to classify each statement as either \"POSITIVE\" or \"NEGATIVE\". The hypothesis made in [problem understanding](01_problem-understanding.ipynb) could have been only validated partly as a positive sentiment does not automatically mean true statement.\n",
    "\n",
    "All in all, the main hypothesis as stated in [problem understanding](01_problem-understanding.ipynb) can be validated. It stated that a fake-news model can be implemented only using the statements itself as well as the metadata of this statement. A LSTM model showed that using two kinds of features, text data and encoded categorical data, was sufficient to train a model supporting this hypothesis.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
