{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Fake News Detection\n",
    "\n",
    "By Felix Daubner - Hochschule der Medien\n",
    "\n",
    "Module 'Supervised and Unsupervised Learning' - Prof. Dr.-Ing. Johannes Maucher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Flatten, Dense, LSTM, Conv1D, Flatten, MaxPooling1D, Dropout, Bidirectional, Input, Concatenate\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "from gensim.models import KeyedVectors\n",
    "import altair as alt\n",
    "\n",
    "NUM_WORDS=3000\n",
    "MAX_SEQUENCE_LEN = 57\n",
    "NUM_CAT = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareFeatures(X):\n",
    "    X_token = np.array(X[\"token\"].apply(np.asarray))\n",
    "    X_token = np.array([arr for arr in X_token])\n",
    "\n",
    "    X_enc = np.array(X.drop([\"token\"], axis=1).apply(np.array))\n",
    "\n",
    "    return X_token, X_enc\n",
    "\n",
    "def prepareTarget(y):\n",
    "    return np.array(y)\n",
    "\n",
    "def visualizeHistory(history):\n",
    "\n",
    "    l, p, v_l, v_p = history.history.keys()\n",
    "\n",
    "    data = pd.DataFrame({\"epoch\": history.epoch,\n",
    "            \"loss\": history.history[l],\n",
    "            \"val_loss\": history.history[v_l],\n",
    "            \"precision\": history.history[p],\n",
    "            \"val_precision\": history.history[v_p]})\n",
    "    \n",
    "    loss_min = min(data[\"loss\"].min(), data[\"val_loss\"].min())\n",
    "    loss_max = max(data[\"loss\"].max(), data[\"val_loss\"].max())\n",
    "\n",
    "    precision_min = min(data[\"precision\"].min(), data[\"val_precision\"].min())\n",
    "    precision_max = max(data[\"precision\"].max(), data[\"val_precision\"].max())\n",
    "\n",
    "    data_melted = data.melt('epoch', value_vars=['loss', 'val_loss', 'precision', 'val_precision'], var_name='type', value_name='value')\n",
    "    \n",
    "    data_loss = data_melted[data_melted[\"type\"].isin([\"loss\", \"val_loss\"])]\n",
    "    loss = alt.Chart(data_loss).mark_line().encode(\n",
    "        x = \"epoch\",\n",
    "        y = alt.Y(\"value\", scale = alt.Scale(domain=[loss_min, loss_max])),\n",
    "        color = alt.Color(\"type\", legend=alt.Legend(orient=\"right\"))\n",
    "    ).properties(\n",
    "        title = \"Training and Validation Loss over epochs\"\n",
    "    )\n",
    "\n",
    "    data_precision = data_melted[data_melted[\"type\"].isin([\"precision\", \"val_precision\"])]\n",
    "    precision = alt.Chart(data_precision).mark_line().encode(\n",
    "        x = \"epoch\",\n",
    "        y = alt.Y(\"value\", scale = alt.Scale(domain=[precision_min, precision_max])),\n",
    "        color = alt.Color(\"type\", legend=alt.Legend(orient=\"right\"))\n",
    "    ).properties(\n",
    "        title = \"Training and Validation Precision over epochs\"\n",
    "    )\n",
    "\n",
    "    return alt.hconcat(loss, precision).resolve_scale(color=\"independent\")\n",
    "\n",
    "\n",
    "def performanceReport(model, X_train, y_train, X_val, y_val):\n",
    "    y_pred_train = (model.predict(X_train) > 0.5).astype(int)\n",
    "    y_pred_val = (model.predict(X_val) > 0.5).astype(int)\n",
    "\n",
    "    print(\"\\nClassifcation Report of Performance on Training data\")\n",
    "    print(classification_report(y_train, y_pred_train))\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"* \"*10)\n",
    "\n",
    "    print(\"\\nClassifcation Report of Performance on Validation data\")\n",
    "    print(classification_report(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section contains the model training and feature selection. Different types of models should be trained and then compared to find out which model fits the challenge, to determine whether a political statement was fake-news or true, best. There are three types of models to be compared: MLP, CNN and LSTM. Those models should also vary in terms of hyperparameters like layers, neurons, optimization and else. The best model is evaluated and then optimized in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"data/processed.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['statement', 'channel_Instagram', 'channel_Other', 'channel_TV',\n",
       "       'channel_TikTok', 'channel_X', 'channel_ad', 'channel_article',\n",
       "       'channel_blog', 'channel_campaign', 'channel_debate',\n",
       "       'channel_interview', 'channel_lecture', 'channel_mail',\n",
       "       'channel_podcast', 'channel_presentation', 'channel_press',\n",
       "       'channel_social media', 'channel_speech', 'channel_talk',\n",
       "       'channel_video', 'truth', 'token', 'statement_stop', 'token_stop'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting defining the different models, the data is prepared for the training process. The neural network to be trained only takes numpy arrays as input. Thus, the data currently saved as a pandas DataFrame is converted in to a numpy array. In this conversion process, only \"token\", the encoded channel and issue columns and \"truth\" are kept meaning column 'statement' is dropped as it can not be used for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After splitting the data into features and target, the features still have to preprared for training by splitting the encoded categorical data from the tokenized and padded statements. The statement data has to be taken care of using an Embedding Layer while a Dense layer is sufficient to handle the encoded categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop([\"statement\", \"statement_stop\", \"token_stop\", \"truth\"], axis=1)\n",
    "y = data[\"truth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_token, X_train_enc = prepareFeatures(X_train)\n",
    "X_val_token, X_val_enc = prepareFeatures(X_val)\n",
    "y_train = prepareTarget(y_train)\n",
    "y_val = prepareTarget(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_json(\"data/LIAR_processed.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop([\"statement\", \"statement_stop\", \"token_stop\", \"truth\"], axis=1)\n",
    "y_test = test[\"truth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_token, X_test_enc = prepareFeatures(X_test)\n",
    "y_test = prepareTarget(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at fake-news detection, it is decided which of accuracy, precision or recall should be optimized. Most often, accuracy is not a good metric as it doesn't include the cost of mis-predicting. That's why either precision or recall should be used.\n",
    "The worst case at fake-news is when a fake-news is not identified as fake-news. Whereas the other way, a true statement being classified as fake-news does not harm in the same way. Translating this into the terms of this project means a false positive (\"a statement which is 'fake' (0) gets classified as 'true' (1)\") is worse than a false negative (\"a statement which is 'true' (1) gets classified as 'false' (0)\"). The metrics focusing on optimizing the false positives is precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, four different types models are trained and evaluated. Based on those evaluations, the best model is chosen and optimized until pre-defined metrics reach their peak. The evaluation for the best model are done using all available features of the data. In the following section [Optimiziation](07_evaluation-optimization.ipynb) the most useful features and hyperparameters of the model are chosen until the best model is reached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = KeyedVectors.load_word2vec_format(\"wiki-news-300d-1M.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tokenizer/tokenizer.pickle\", \"rb\") as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300  \n",
    "word_index = tokenizer.word_index \n",
    "num_words = min(len(word_index) + 1, NUM_WORDS)  \n",
    "\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i < num_words:\n",
    "        if word in word2vec.key_to_index:\n",
    "            embedding_vector = word2vec[word]\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = Input(shape=(MAX_SEQUENCE_LEN,), name=\"text_input\")\n",
    "categorical_input = Input(shape=(NUM_CAT,), name=\"categorical_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = Embedding(NUM_WORDS, embedding_dim, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LEN, trainable=False)(text_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Dense(32, activation=\"relu\")(categorical_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedforward Neural Nerwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_flatten_text = Flatten()(emb)\n",
    "\n",
    "ff_combined = Concatenate()([ff_flatten_text, cat])\n",
    "ff_dense1 = Dense(128, activation=\"relu\")(ff_combined)\n",
    "ff_drop = Dropout(0.3)(ff_dense1)\n",
    "ff_dense2 = Dense(64, activation=\"relu\")(ff_drop)\n",
    "ff_output = Dense(1, activation=\"sigmoid\")(ff_dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text_input (InputLayer)        [(None, 57)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 57, 300)      900000      ['text_input[0][0]']             \n",
      "                                                                                                  \n",
      " categorical_input (InputLayer)  [(None, 20)]        0           []                               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 17100)        0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 32)           672         ['categorical_input[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 17132)        0           ['flatten[0][0]',                \n",
      "                                                                  'dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          2193024     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 128)          0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 64)           8256        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            65          ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,102,017\n",
      "Trainable params: 2,202,017\n",
      "Non-trainable params: 900,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ff = Model(inputs=[categorical_input, text_input], outputs=ff_output)\n",
    "ff.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff.compile(optimizer=\"sgd\", loss=\"binary_crossentropy\", metrics=[keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "111/111 [==============================] - 1s 12ms/step - loss: 0.5031 - precision: 0.7585 - val_loss: 0.5267 - val_precision: 0.7570\n",
      "Epoch 2/20\n",
      "111/111 [==============================] - 1s 12ms/step - loss: 0.4937 - precision: 0.7655 - val_loss: 0.5181 - val_precision: 0.7288\n",
      "Epoch 3/20\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 0.4821 - precision: 0.7713 - val_loss: 0.5117 - val_precision: 0.7467\n",
      "Epoch 4/20\n",
      "111/111 [==============================] - 1s 12ms/step - loss: 0.4741 - precision: 0.7767 - val_loss: 0.5070 - val_precision: 0.7365\n",
      "Epoch 5/20\n",
      "111/111 [==============================] - 1s 11ms/step - loss: 0.4645 - precision: 0.7800 - val_loss: 0.5044 - val_precision: 0.7311\n",
      "Epoch 6/20\n",
      "111/111 [==============================] - 1s 12ms/step - loss: 0.4560 - precision: 0.7893 - val_loss: 0.4985 - val_precision: 0.7383\n",
      "Epoch 7/20\n",
      "111/111 [==============================] - 1s 12ms/step - loss: 0.4472 - precision: 0.7921 - val_loss: 0.4991 - val_precision: 0.7862\n",
      "Epoch 8/20\n",
      "111/111 [==============================] - 1s 12ms/step - loss: 0.4394 - precision: 0.7986 - val_loss: 0.4871 - val_precision: 0.7595\n",
      "Epoch 9/20\n",
      "111/111 [==============================] - 1s 11ms/step - loss: 0.4272 - precision: 0.8056 - val_loss: 0.4845 - val_precision: 0.7713\n",
      "Epoch 10/20\n",
      "111/111 [==============================] - 1s 11ms/step - loss: 0.4205 - precision: 0.8086 - val_loss: 0.4782 - val_precision: 0.7659\n",
      "Epoch 11/20\n",
      "111/111 [==============================] - 1s 11ms/step - loss: 0.4124 - precision: 0.8152 - val_loss: 0.4921 - val_precision: 0.7176\n",
      "Epoch 12/20\n",
      "111/111 [==============================] - 1s 12ms/step - loss: 0.4031 - precision: 0.8168 - val_loss: 0.4912 - val_precision: 0.7172\n",
      "Epoch 13/20\n",
      "111/111 [==============================] - 1s 10ms/step - loss: 0.3942 - precision: 0.8271 - val_loss: 0.4664 - val_precision: 0.7650\n",
      "Epoch 14/20\n",
      "111/111 [==============================] - 1s 11ms/step - loss: 0.3837 - precision: 0.8300 - val_loss: 0.4664 - val_precision: 0.7579\n",
      "Epoch 15/20\n",
      "111/111 [==============================] - 1s 11ms/step - loss: 0.3767 - precision: 0.8335 - val_loss: 0.4593 - val_precision: 0.7747\n",
      "Epoch 16/20\n",
      "111/111 [==============================] - 1s 11ms/step - loss: 0.3700 - precision: 0.8403 - val_loss: 0.4667 - val_precision: 0.7428\n",
      "Epoch 17/20\n",
      "111/111 [==============================] - 1s 11ms/step - loss: 0.3631 - precision: 0.8419 - val_loss: 0.4539 - val_precision: 0.7978\n",
      "Epoch 18/20\n",
      "111/111 [==============================] - 1s 11ms/step - loss: 0.3493 - precision: 0.8524 - val_loss: 0.4497 - val_precision: 0.7788\n",
      "Epoch 19/20\n",
      "111/111 [==============================] - 1s 11ms/step - loss: 0.3443 - precision: 0.8528 - val_loss: 0.4441 - val_precision: 0.7886\n",
      "Epoch 20/20\n",
      "111/111 [==============================] - 1s 10ms/step - loss: 0.3374 - precision: 0.8589 - val_loss: 0.4410 - val_precision: 0.7952\n"
     ]
    }
   ],
   "source": [
    "ff_hist = ff.fit([X_train_enc, X_train_token], y_train, epochs=20, batch_size=128, validation_data=([X_val_enc, X_val_token], y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-a06881f8765e41c1acb2a23c83986020.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-a06881f8765e41c1acb2a23c83986020.vega-embed details,\n",
       "  #altair-viz-a06881f8765e41c1acb2a23c83986020.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-a06881f8765e41c1acb2a23c83986020\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-a06881f8765e41c1acb2a23c83986020\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-a06881f8765e41c1acb2a23c83986020\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"hconcat\": [{\"data\": {\"name\": \"data-dd4d1aa324680aa4250fc4af7193fb50\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"type\", \"legend\": {\"orient\": \"right\"}, \"type\": \"nominal\"}, \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"scale\": {\"domain\": [0.33736714720726013, 0.5267208218574524]}, \"type\": \"quantitative\"}}, \"title\": \"Training and Validation Loss over epochs\"}, {\"data\": {\"name\": \"data-d1e9ed848efa50be39f214766d4bcd6a\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"type\", \"legend\": {\"orient\": \"right\"}, \"type\": \"nominal\"}, \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"scale\": {\"domain\": [0.7171828150749207, 0.8589125871658325]}, \"type\": \"quantitative\"}}, \"title\": \"Training and Validation Precision over epochs\"}], \"resolve\": {\"scale\": {\"color\": \"independent\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-dd4d1aa324680aa4250fc4af7193fb50\": [{\"epoch\": 0, \"type\": \"loss\", \"value\": 0.5030531287193298}, {\"epoch\": 1, \"type\": \"loss\", \"value\": 0.493701696395874}, {\"epoch\": 2, \"type\": \"loss\", \"value\": 0.4820520281791687}, {\"epoch\": 3, \"type\": \"loss\", \"value\": 0.47410351037979126}, {\"epoch\": 4, \"type\": \"loss\", \"value\": 0.46446165442466736}, {\"epoch\": 5, \"type\": \"loss\", \"value\": 0.456018328666687}, {\"epoch\": 6, \"type\": \"loss\", \"value\": 0.4472285211086273}, {\"epoch\": 7, \"type\": \"loss\", \"value\": 0.4394092559814453}, {\"epoch\": 8, \"type\": \"loss\", \"value\": 0.42721492052078247}, {\"epoch\": 9, \"type\": \"loss\", \"value\": 0.4205266535282135}, {\"epoch\": 10, \"type\": \"loss\", \"value\": 0.4123842716217041}, {\"epoch\": 11, \"type\": \"loss\", \"value\": 0.4030660390853882}, {\"epoch\": 12, \"type\": \"loss\", \"value\": 0.3942191004753113}, {\"epoch\": 13, \"type\": \"loss\", \"value\": 0.38369831442832947}, {\"epoch\": 14, \"type\": \"loss\", \"value\": 0.37666407227516174}, {\"epoch\": 15, \"type\": \"loss\", \"value\": 0.37000772356987}, {\"epoch\": 16, \"type\": \"loss\", \"value\": 0.3631099462509155}, {\"epoch\": 17, \"type\": \"loss\", \"value\": 0.34932267665863037}, {\"epoch\": 18, \"type\": \"loss\", \"value\": 0.3443417549133301}, {\"epoch\": 19, \"type\": \"loss\", \"value\": 0.33736714720726013}, {\"epoch\": 0, \"type\": \"val_loss\", \"value\": 0.5267208218574524}, {\"epoch\": 1, \"type\": \"val_loss\", \"value\": 0.5180605053901672}, {\"epoch\": 2, \"type\": \"val_loss\", \"value\": 0.5116822719573975}, {\"epoch\": 3, \"type\": \"val_loss\", \"value\": 0.5069701075553894}, {\"epoch\": 4, \"type\": \"val_loss\", \"value\": 0.5043924450874329}, {\"epoch\": 5, \"type\": \"val_loss\", \"value\": 0.4984750747680664}, {\"epoch\": 6, \"type\": \"val_loss\", \"value\": 0.499142587184906}, {\"epoch\": 7, \"type\": \"val_loss\", \"value\": 0.48705917596817017}, {\"epoch\": 8, \"type\": \"val_loss\", \"value\": 0.4845277667045593}, {\"epoch\": 9, \"type\": \"val_loss\", \"value\": 0.4782216548919678}, {\"epoch\": 10, \"type\": \"val_loss\", \"value\": 0.4920675754547119}, {\"epoch\": 11, \"type\": \"val_loss\", \"value\": 0.4912055730819702}, {\"epoch\": 12, \"type\": \"val_loss\", \"value\": 0.4663757383823395}, {\"epoch\": 13, \"type\": \"val_loss\", \"value\": 0.4664006531238556}, {\"epoch\": 14, \"type\": \"val_loss\", \"value\": 0.4593014419078827}, {\"epoch\": 15, \"type\": \"val_loss\", \"value\": 0.46666577458381653}, {\"epoch\": 16, \"type\": \"val_loss\", \"value\": 0.45392921566963196}, {\"epoch\": 17, \"type\": \"val_loss\", \"value\": 0.4496711492538452}, {\"epoch\": 18, \"type\": \"val_loss\", \"value\": 0.4441477656364441}, {\"epoch\": 19, \"type\": \"val_loss\", \"value\": 0.44098401069641113}], \"data-d1e9ed848efa50be39f214766d4bcd6a\": [{\"epoch\": 0, \"type\": \"precision\", \"value\": 0.7585359215736389}, {\"epoch\": 1, \"type\": \"precision\", \"value\": 0.7654843330383301}, {\"epoch\": 2, \"type\": \"precision\", \"value\": 0.7712613940238953}, {\"epoch\": 3, \"type\": \"precision\", \"value\": 0.7767069339752197}, {\"epoch\": 4, \"type\": \"precision\", \"value\": 0.7799865007400513}, {\"epoch\": 5, \"type\": \"precision\", \"value\": 0.7893235683441162}, {\"epoch\": 6, \"type\": \"precision\", \"value\": 0.792116641998291}, {\"epoch\": 7, \"type\": \"precision\", \"value\": 0.7985798120498657}, {\"epoch\": 8, \"type\": \"precision\", \"value\": 0.8055820465087891}, {\"epoch\": 9, \"type\": \"precision\", \"value\": 0.808571457862854}, {\"epoch\": 10, \"type\": \"precision\", \"value\": 0.8152337074279785}, {\"epoch\": 11, \"type\": \"precision\", \"value\": 0.8167928457260132}, {\"epoch\": 12, \"type\": \"precision\", \"value\": 0.827064573764801}, {\"epoch\": 13, \"type\": \"precision\", \"value\": 0.8299837112426758}, {\"epoch\": 14, \"type\": \"precision\", \"value\": 0.833469808101654}, {\"epoch\": 15, \"type\": \"precision\", \"value\": 0.8402625918388367}, {\"epoch\": 16, \"type\": \"precision\", \"value\": 0.8419192433357239}, {\"epoch\": 17, \"type\": \"precision\", \"value\": 0.8524295687675476}, {\"epoch\": 18, \"type\": \"precision\", \"value\": 0.8528203964233398}, {\"epoch\": 19, \"type\": \"precision\", \"value\": 0.8589125871658325}, {\"epoch\": 0, \"type\": \"val_precision\", \"value\": 0.7569676637649536}, {\"epoch\": 1, \"type\": \"val_precision\", \"value\": 0.7287977337837219}, {\"epoch\": 2, \"type\": \"val_precision\", \"value\": 0.7466974854469299}, {\"epoch\": 3, \"type\": \"val_precision\", \"value\": 0.7365138530731201}, {\"epoch\": 4, \"type\": \"val_precision\", \"value\": 0.7311306595802307}, {\"epoch\": 5, \"type\": \"val_precision\", \"value\": 0.7382776737213135}, {\"epoch\": 6, \"type\": \"val_precision\", \"value\": 0.7862332463264465}, {\"epoch\": 7, \"type\": \"val_precision\", \"value\": 0.7594771385192871}, {\"epoch\": 8, \"type\": \"val_precision\", \"value\": 0.7712802886962891}, {\"epoch\": 9, \"type\": \"val_precision\", \"value\": 0.7659083604812622}, {\"epoch\": 10, \"type\": \"val_precision\", \"value\": 0.7175697684288025}, {\"epoch\": 11, \"type\": \"val_precision\", \"value\": 0.7171828150749207}, {\"epoch\": 12, \"type\": \"val_precision\", \"value\": 0.7650375962257385}, {\"epoch\": 13, \"type\": \"val_precision\", \"value\": 0.7578530311584473}, {\"epoch\": 14, \"type\": \"val_precision\", \"value\": 0.7746884226799011}, {\"epoch\": 15, \"type\": \"val_precision\", \"value\": 0.7428160905838013}, {\"epoch\": 16, \"type\": \"val_precision\", \"value\": 0.7978427410125732}, {\"epoch\": 17, \"type\": \"val_precision\", \"value\": 0.778800368309021}, {\"epoch\": 18, \"type\": \"val_precision\", \"value\": 0.7885547876358032}, {\"epoch\": 19, \"type\": \"val_precision\", \"value\": 0.7952162623405457}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualizeHistory(ff_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441/441 [==============================] - 1s 1ms/step\n",
      "189/189 [==============================] - 0s 1ms/step\n",
      "\n",
      "Classifcation Report of Performance on Training data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89      7000\n",
      "           1       0.89      0.89      0.89      7109\n",
      "\n",
      "    accuracy                           0.89     14109\n",
      "   macro avg       0.89      0.89      0.89     14109\n",
      "weighted avg       0.89      0.89      0.89     14109\n",
      "\n",
      "\n",
      "\n",
      "* * * * * * * * * * \n",
      "\n",
      "Classifcation Report of Performance on Validation data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      3078\n",
      "           1       0.80      0.82      0.81      2969\n",
      "\n",
      "    accuracy                           0.81      6047\n",
      "   macro avg       0.81      0.81      0.81      6047\n",
      "weighted avg       0.81      0.81      0.81      6047\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performanceReport(ff, [X_train_enc, X_train_token], y_train, [X_val_enc, X_val_token], y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_ = LSTM(64)(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_combined = Concatenate()([lstm_, cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_dense1 = Dense(64, activation='relu')(lstm_combined)\n",
    "lstm_drop1 = Dropout(0.2)(lstm_dense1)\n",
    "lstm_dense2 = Dense(32, activation='relu')(lstm_drop1)\n",
    "lstm_drop2 = Dropout(0.4)(lstm_dense2)\n",
    "lstm_output = Dense(1, activation='sigmoid')(lstm_drop2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text_input (InputLayer)        [(None, 57)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 57, 300)      900000      ['text_input[0][0]']             \n",
      "                                                                                                  \n",
      " categorical_input (InputLayer)  [(None, 20)]        0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 64)           93440       ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 32)           672         ['categorical_input[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 96)           0           ['lstm[0][0]',                   \n",
      "                                                                  'dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 64)           6208        ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 64)           0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 32)           2080        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 32)           0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 1)            33          ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,002,433\n",
      "Trainable params: 102,433\n",
      "Non-trainable params: 900,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = Model(inputs=[categorical_input, text_input], outputs=lstm_output)\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.compile(optimizer=\"sgd\", loss=\"binary_crossentropy\", metrics=[keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "111/111 [==============================] - 7s 54ms/step - loss: 0.6953 - precision_1: 0.5028 - val_loss: 0.6913 - val_precision_1: 0.5393\n",
      "Epoch 2/20\n",
      "111/111 [==============================] - 6s 51ms/step - loss: 0.6915 - precision_1: 0.5314 - val_loss: 0.6881 - val_precision_1: 0.5593\n",
      "Epoch 3/20\n",
      "111/111 [==============================] - 6s 52ms/step - loss: 0.6879 - precision_1: 0.5540 - val_loss: 0.6852 - val_precision_1: 0.5795\n",
      "Epoch 4/20\n",
      "111/111 [==============================] - 6s 53ms/step - loss: 0.6855 - precision_1: 0.5683 - val_loss: 0.6827 - val_precision_1: 0.5887\n",
      "Epoch 5/20\n",
      "111/111 [==============================] - 6s 53ms/step - loss: 0.6837 - precision_1: 0.5745 - val_loss: 0.6801 - val_precision_1: 0.5955\n",
      "Epoch 6/20\n",
      "111/111 [==============================] - 6s 54ms/step - loss: 0.6808 - precision_1: 0.5881 - val_loss: 0.6777 - val_precision_1: 0.5992\n",
      "Epoch 7/20\n",
      "111/111 [==============================] - 6s 53ms/step - loss: 0.6789 - precision_1: 0.5946 - val_loss: 0.6749 - val_precision_1: 0.6045\n",
      "Epoch 8/20\n",
      "111/111 [==============================] - 6s 52ms/step - loss: 0.6758 - precision_1: 0.6031 - val_loss: 0.6722 - val_precision_1: 0.6027\n",
      "Epoch 9/20\n",
      "111/111 [==============================] - 6s 53ms/step - loss: 0.6734 - precision_1: 0.6085 - val_loss: 0.6692 - val_precision_1: 0.6056\n",
      "Epoch 10/20\n",
      "111/111 [==============================] - 6s 53ms/step - loss: 0.6707 - precision_1: 0.6131 - val_loss: 0.6659 - val_precision_1: 0.6180\n",
      "Epoch 11/20\n",
      "111/111 [==============================] - 6s 53ms/step - loss: 0.6677 - precision_1: 0.6105 - val_loss: 0.6623 - val_precision_1: 0.6316\n",
      "Epoch 12/20\n",
      "111/111 [==============================] - 6s 53ms/step - loss: 0.6648 - precision_1: 0.6137 - val_loss: 0.6589 - val_precision_1: 0.6302\n",
      "Epoch 13/20\n",
      "111/111 [==============================] - 6s 54ms/step - loss: 0.6619 - precision_1: 0.6231 - val_loss: 0.6551 - val_precision_1: 0.6362\n",
      "Epoch 14/20\n",
      "111/111 [==============================] - 6s 52ms/step - loss: 0.6576 - precision_1: 0.6327 - val_loss: 0.6514 - val_precision_1: 0.6370\n",
      "Epoch 15/20\n",
      "111/111 [==============================] - 6s 53ms/step - loss: 0.6550 - precision_1: 0.6322 - val_loss: 0.6475 - val_precision_1: 0.6409\n",
      "Epoch 16/20\n",
      "111/111 [==============================] - 6s 53ms/step - loss: 0.6506 - precision_1: 0.6369 - val_loss: 0.6435 - val_precision_1: 0.6403\n",
      "Epoch 17/20\n",
      "111/111 [==============================] - 6s 52ms/step - loss: 0.6494 - precision_1: 0.6360 - val_loss: 0.6404 - val_precision_1: 0.6375\n",
      "Epoch 18/20\n",
      "111/111 [==============================] - 6s 54ms/step - loss: 0.6439 - precision_1: 0.6368 - val_loss: 0.6364 - val_precision_1: 0.6371\n",
      "Epoch 19/20\n",
      "111/111 [==============================] - 6s 54ms/step - loss: 0.6420 - precision_1: 0.6390 - val_loss: 0.6326 - val_precision_1: 0.6382\n",
      "Epoch 20/20\n",
      "111/111 [==============================] - 6s 53ms/step - loss: 0.6363 - precision_1: 0.6451 - val_loss: 0.6285 - val_precision_1: 0.6383\n"
     ]
    }
   ],
   "source": [
    "lstm_hist = lstm.fit([X_train_enc, X_train_token], y_train, batch_size=128, epochs=20, validation_data=([X_val_enc, X_val_token], y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-794299b38fa3416793fba65add5c5571.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-794299b38fa3416793fba65add5c5571.vega-embed details,\n",
       "  #altair-viz-794299b38fa3416793fba65add5c5571.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-794299b38fa3416793fba65add5c5571\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-794299b38fa3416793fba65add5c5571\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-794299b38fa3416793fba65add5c5571\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"hconcat\": [{\"data\": {\"name\": \"data-e43f033078a0fe0c03293a42e1e289bd\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"type\", \"legend\": {\"orient\": \"right\"}, \"type\": \"nominal\"}, \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"scale\": {\"domain\": [0.6285490393638611, 0.6953498125076294]}, \"type\": \"quantitative\"}}, \"title\": \"Training and Validation Loss over epochs\"}, {\"data\": {\"name\": \"data-9d44ca6164b7d3295d11ca991e0fa97f\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"type\", \"legend\": {\"orient\": \"right\"}, \"type\": \"nominal\"}, \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"scale\": {\"domain\": [0.5027669668197632, 0.6450685858726501]}, \"type\": \"quantitative\"}}, \"title\": \"Training and Validation Precision over epochs\"}], \"resolve\": {\"scale\": {\"color\": \"independent\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-e43f033078a0fe0c03293a42e1e289bd\": [{\"epoch\": 0, \"type\": \"loss\", \"value\": 0.6953498125076294}, {\"epoch\": 1, \"type\": \"loss\", \"value\": 0.691475510597229}, {\"epoch\": 2, \"type\": \"loss\", \"value\": 0.6878812313079834}, {\"epoch\": 3, \"type\": \"loss\", \"value\": 0.6855126023292542}, {\"epoch\": 4, \"type\": \"loss\", \"value\": 0.6837294697761536}, {\"epoch\": 5, \"type\": \"loss\", \"value\": 0.6807961463928223}, {\"epoch\": 6, \"type\": \"loss\", \"value\": 0.6789256930351257}, {\"epoch\": 7, \"type\": \"loss\", \"value\": 0.675812304019928}, {\"epoch\": 8, \"type\": \"loss\", \"value\": 0.6734240651130676}, {\"epoch\": 9, \"type\": \"loss\", \"value\": 0.6707218289375305}, {\"epoch\": 10, \"type\": \"loss\", \"value\": 0.6676738858222961}, {\"epoch\": 11, \"type\": \"loss\", \"value\": 0.664820671081543}, {\"epoch\": 12, \"type\": \"loss\", \"value\": 0.6618617177009583}, {\"epoch\": 13, \"type\": \"loss\", \"value\": 0.6575819253921509}, {\"epoch\": 14, \"type\": \"loss\", \"value\": 0.6550043821334839}, {\"epoch\": 15, \"type\": \"loss\", \"value\": 0.6505559682846069}, {\"epoch\": 16, \"type\": \"loss\", \"value\": 0.6494337916374207}, {\"epoch\": 17, \"type\": \"loss\", \"value\": 0.6438636779785156}, {\"epoch\": 18, \"type\": \"loss\", \"value\": 0.6419721245765686}, {\"epoch\": 19, \"type\": \"loss\", \"value\": 0.6362606883049011}, {\"epoch\": 0, \"type\": \"val_loss\", \"value\": 0.6912586688995361}, {\"epoch\": 1, \"type\": \"val_loss\", \"value\": 0.6880909204483032}, {\"epoch\": 2, \"type\": \"val_loss\", \"value\": 0.6852214336395264}, {\"epoch\": 3, \"type\": \"val_loss\", \"value\": 0.6827069520950317}, {\"epoch\": 4, \"type\": \"val_loss\", \"value\": 0.6800872087478638}, {\"epoch\": 5, \"type\": \"val_loss\", \"value\": 0.6776508688926697}, {\"epoch\": 6, \"type\": \"val_loss\", \"value\": 0.6749303340911865}, {\"epoch\": 7, \"type\": \"val_loss\", \"value\": 0.6722050905227661}, {\"epoch\": 8, \"type\": \"val_loss\", \"value\": 0.6692158579826355}, {\"epoch\": 9, \"type\": \"val_loss\", \"value\": 0.6659252047538757}, {\"epoch\": 10, \"type\": \"val_loss\", \"value\": 0.6622968912124634}, {\"epoch\": 11, \"type\": \"val_loss\", \"value\": 0.6588857769966125}, {\"epoch\": 12, \"type\": \"val_loss\", \"value\": 0.6550652980804443}, {\"epoch\": 13, \"type\": \"val_loss\", \"value\": 0.651368260383606}, {\"epoch\": 14, \"type\": \"val_loss\", \"value\": 0.6474995017051697}, {\"epoch\": 15, \"type\": \"val_loss\", \"value\": 0.6434557437896729}, {\"epoch\": 16, \"type\": \"val_loss\", \"value\": 0.6404475569725037}, {\"epoch\": 17, \"type\": \"val_loss\", \"value\": 0.6364461779594421}, {\"epoch\": 18, \"type\": \"val_loss\", \"value\": 0.6326063275337219}, {\"epoch\": 19, \"type\": \"val_loss\", \"value\": 0.6285490393638611}], \"data-9d44ca6164b7d3295d11ca991e0fa97f\": [{\"epoch\": 0, \"type\": \"precision\", \"value\": 0.5027669668197632}, {\"epoch\": 1, \"type\": \"precision\", \"value\": 0.5313578844070435}, {\"epoch\": 2, \"type\": \"precision\", \"value\": 0.5539941787719727}, {\"epoch\": 3, \"type\": \"precision\", \"value\": 0.568280816078186}, {\"epoch\": 4, \"type\": \"precision\", \"value\": 0.5745078325271606}, {\"epoch\": 5, \"type\": \"precision\", \"value\": 0.5880976915359497}, {\"epoch\": 6, \"type\": \"precision\", \"value\": 0.5945562720298767}, {\"epoch\": 7, \"type\": \"precision\", \"value\": 0.6030789613723755}, {\"epoch\": 8, \"type\": \"precision\", \"value\": 0.6085338592529297}, {\"epoch\": 9, \"type\": \"precision\", \"value\": 0.6130914092063904}, {\"epoch\": 10, \"type\": \"precision\", \"value\": 0.6104742288589478}, {\"epoch\": 11, \"type\": \"precision\", \"value\": 0.6137063503265381}, {\"epoch\": 12, \"type\": \"precision\", \"value\": 0.6231260299682617}, {\"epoch\": 13, \"type\": \"precision\", \"value\": 0.6326858401298523}, {\"epoch\": 14, \"type\": \"precision\", \"value\": 0.6322341561317444}, {\"epoch\": 15, \"type\": \"precision\", \"value\": 0.6368921995162964}, {\"epoch\": 16, \"type\": \"precision\", \"value\": 0.6360200047492981}, {\"epoch\": 17, \"type\": \"precision\", \"value\": 0.6367565989494324}, {\"epoch\": 18, \"type\": \"precision\", \"value\": 0.638957679271698}, {\"epoch\": 19, \"type\": \"precision\", \"value\": 0.6450685858726501}, {\"epoch\": 0, \"type\": \"val_precision\", \"value\": 0.5392892360687256}, {\"epoch\": 1, \"type\": \"val_precision\", \"value\": 0.5592823624610901}, {\"epoch\": 2, \"type\": \"val_precision\", \"value\": 0.5795207023620605}, {\"epoch\": 3, \"type\": \"val_precision\", \"value\": 0.588674008846283}, {\"epoch\": 4, \"type\": \"val_precision\", \"value\": 0.5955254435539246}, {\"epoch\": 5, \"type\": \"val_precision\", \"value\": 0.5992298722267151}, {\"epoch\": 6, \"type\": \"val_precision\", \"value\": 0.6045215129852295}, {\"epoch\": 7, \"type\": \"val_precision\", \"value\": 0.602706789970398}, {\"epoch\": 8, \"type\": \"val_precision\", \"value\": 0.6055956482887268}, {\"epoch\": 9, \"type\": \"val_precision\", \"value\": 0.618005633354187}, {\"epoch\": 10, \"type\": \"val_precision\", \"value\": 0.6316139698028564}, {\"epoch\": 11, \"type\": \"val_precision\", \"value\": 0.6301983594894409}, {\"epoch\": 12, \"type\": \"val_precision\", \"value\": 0.6362126469612122}, {\"epoch\": 13, \"type\": \"val_precision\", \"value\": 0.6369710564613342}, {\"epoch\": 14, \"type\": \"val_precision\", \"value\": 0.6409090757369995}, {\"epoch\": 15, \"type\": \"val_precision\", \"value\": 0.64034503698349}, {\"epoch\": 16, \"type\": \"val_precision\", \"value\": 0.6375037431716919}, {\"epoch\": 17, \"type\": \"val_precision\", \"value\": 0.6370725631713867}, {\"epoch\": 18, \"type\": \"val_precision\", \"value\": 0.6382273435592651}, {\"epoch\": 19, \"type\": \"val_precision\", \"value\": 0.6383107304573059}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualizeHistory(lstm_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441/441 [==============================] - 4s 9ms/step\n",
      "189/189 [==============================] - 2s 9ms/step\n",
      "\n",
      "Classifcation Report of Performance on Training data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.57      0.63      7000\n",
      "           1       0.64      0.76      0.70      7109\n",
      "\n",
      "    accuracy                           0.67     14109\n",
      "   macro avg       0.67      0.66      0.66     14109\n",
      "weighted avg       0.67      0.67      0.66     14109\n",
      "\n",
      "\n",
      "\n",
      "* * * * * * * * * * \n",
      "\n",
      "Classifcation Report of Performance on Validation data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.57      0.63      3078\n",
      "           1       0.63      0.74      0.68      2969\n",
      "\n",
      "    accuracy                           0.66      6047\n",
      "   macro avg       0.66      0.66      0.66      6047\n",
      "weighted avg       0.66      0.66      0.66      6047\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performanceReport(lstm, [X_train_enc, X_train_token], y_train, [X_val_enc, X_val_token], y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-directional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "blstm_ = Bidirectional(LSTM(128))(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "blstm_combined = Concatenate()([blstm_, cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "blstm_dense1 = Dense(64, activation='relu')(blstm_combined)\n",
    "blstm_drop1 = Dropout(0.2)(blstm_dense1)\n",
    "blstm_output = Dense(1, activation='sigmoid')(blstm_drop1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text_input (InputLayer)        [(None, 57)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 57, 300)      900000      ['text_input[0][0]']             \n",
      "                                                                                                  \n",
      " categorical_input (InputLayer)  [(None, 20)]        0           []                               \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 256)          439296      ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 32)           672         ['categorical_input[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 288)          0           ['bidirectional[0][0]',          \n",
      "                                                                  'dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 64)           18496       ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 64)           0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 1)            65          ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,358,529\n",
      "Trainable params: 458,529\n",
      "Non-trainable params: 900,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "blstm = Model(inputs=[categorical_input, text_input], outputs=blstm_output)\n",
    "blstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "blstm.compile(optimizer=\"sgd\", loss=\"binary_crossentropy\", metrics=[keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "111/111 [==============================] - 15s 122ms/step - loss: 0.6972 - precision_2: 0.4419 - val_loss: 0.6943 - val_precision_2: 0.4782\n",
      "Epoch 2/20\n",
      "111/111 [==============================] - 15s 132ms/step - loss: 0.6921 - precision_2: 0.5097 - val_loss: 0.6903 - val_precision_2: 0.5312\n",
      "Epoch 3/20\n",
      "111/111 [==============================] - 14s 130ms/step - loss: 0.6884 - precision_2: 0.5529 - val_loss: 0.6869 - val_precision_2: 0.5539\n",
      "Epoch 4/20\n",
      "111/111 [==============================] - 14s 125ms/step - loss: 0.6848 - precision_2: 0.5835 - val_loss: 0.6835 - val_precision_2: 0.5887\n",
      "Epoch 5/20\n",
      "111/111 [==============================] - 14s 123ms/step - loss: 0.6815 - precision_2: 0.6069 - val_loss: 0.6804 - val_precision_2: 0.6119\n",
      "Epoch 6/20\n",
      "111/111 [==============================] - 13s 120ms/step - loss: 0.6781 - precision_2: 0.6214 - val_loss: 0.6771 - val_precision_2: 0.6371\n",
      "Epoch 7/20\n",
      "111/111 [==============================] - 14s 122ms/step - loss: 0.6750 - precision_2: 0.6352 - val_loss: 0.6742 - val_precision_2: 0.6374\n",
      "Epoch 8/20\n",
      "111/111 [==============================] - 13s 120ms/step - loss: 0.6718 - precision_2: 0.6386 - val_loss: 0.6710 - val_precision_2: 0.6498\n",
      "Epoch 9/20\n",
      "111/111 [==============================] - 14s 127ms/step - loss: 0.6692 - precision_2: 0.6436 - val_loss: 0.6678 - val_precision_2: 0.6511\n",
      "Epoch 10/20\n",
      "111/111 [==============================] - 14s 122ms/step - loss: 0.6655 - precision_2: 0.6456 - val_loss: 0.6645 - val_precision_2: 0.6509\n",
      "Epoch 11/20\n",
      "111/111 [==============================] - 14s 126ms/step - loss: 0.6626 - precision_2: 0.6491 - val_loss: 0.6610 - val_precision_2: 0.6525\n",
      "Epoch 12/20\n",
      "111/111 [==============================] - 13s 121ms/step - loss: 0.6590 - precision_2: 0.6500 - val_loss: 0.6575 - val_precision_2: 0.6521\n",
      "Epoch 13/20\n",
      "111/111 [==============================] - 13s 118ms/step - loss: 0.6552 - precision_2: 0.6539 - val_loss: 0.6537 - val_precision_2: 0.6523\n",
      "Epoch 14/20\n",
      "111/111 [==============================] - 13s 120ms/step - loss: 0.6511 - precision_2: 0.6516 - val_loss: 0.6495 - val_precision_2: 0.6554\n",
      "Epoch 15/20\n",
      "111/111 [==============================] - 14s 122ms/step - loss: 0.6469 - precision_2: 0.6580 - val_loss: 0.6454 - val_precision_2: 0.6552\n",
      "Epoch 16/20\n",
      "111/111 [==============================] - 14s 128ms/step - loss: 0.6437 - precision_2: 0.6553 - val_loss: 0.6416 - val_precision_2: 0.6534\n",
      "Epoch 17/20\n",
      "111/111 [==============================] - 14s 125ms/step - loss: 0.6390 - precision_2: 0.6595 - val_loss: 0.6372 - val_precision_2: 0.6543\n",
      "Epoch 18/20\n",
      "111/111 [==============================] - 14s 123ms/step - loss: 0.6346 - precision_2: 0.6577 - val_loss: 0.6327 - val_precision_2: 0.6548\n",
      "Epoch 19/20\n",
      "111/111 [==============================] - 14s 122ms/step - loss: 0.6299 - precision_2: 0.6578 - val_loss: 0.6281 - val_precision_2: 0.6559\n",
      "Epoch 20/20\n",
      "111/111 [==============================] - 14s 129ms/step - loss: 0.6262 - precision_2: 0.6600 - val_loss: 0.6241 - val_precision_2: 0.6524\n"
     ]
    }
   ],
   "source": [
    "blstm_hist = blstm.fit([X_train_enc, X_train_token], y_train, batch_size=128, epochs=20, validation_data=([X_val_enc, X_val_token], y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-a035f76ed7b74625aa95bde41fcc8b53.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-a035f76ed7b74625aa95bde41fcc8b53.vega-embed details,\n",
       "  #altair-viz-a035f76ed7b74625aa95bde41fcc8b53.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-a035f76ed7b74625aa95bde41fcc8b53\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-a035f76ed7b74625aa95bde41fcc8b53\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-a035f76ed7b74625aa95bde41fcc8b53\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"hconcat\": [{\"data\": {\"name\": \"data-09f931b51a0fe4d9109d867764304e52\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"type\", \"legend\": {\"orient\": \"right\"}, \"type\": \"nominal\"}, \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"scale\": {\"domain\": [0.6240695714950562, 0.6971930265426636]}, \"type\": \"quantitative\"}}, \"title\": \"Training and Validation Loss over epochs\"}, {\"data\": {\"name\": \"data-abeb2bbeb4fb61c3231fcf6349550c85\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"type\", \"legend\": {\"orient\": \"right\"}, \"type\": \"nominal\"}, \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"scale\": {\"domain\": [0.44185134768486023, 0.6600499749183655]}, \"type\": \"quantitative\"}}, \"title\": \"Training and Validation Precision over epochs\"}], \"resolve\": {\"scale\": {\"color\": \"independent\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-09f931b51a0fe4d9109d867764304e52\": [{\"epoch\": 0, \"type\": \"loss\", \"value\": 0.6971930265426636}, {\"epoch\": 1, \"type\": \"loss\", \"value\": 0.6920894980430603}, {\"epoch\": 2, \"type\": \"loss\", \"value\": 0.6884288191795349}, {\"epoch\": 3, \"type\": \"loss\", \"value\": 0.6847578287124634}, {\"epoch\": 4, \"type\": \"loss\", \"value\": 0.681506335735321}, {\"epoch\": 5, \"type\": \"loss\", \"value\": 0.6780807375907898}, {\"epoch\": 6, \"type\": \"loss\", \"value\": 0.6750332117080688}, {\"epoch\": 7, \"type\": \"loss\", \"value\": 0.6717633605003357}, {\"epoch\": 8, \"type\": \"loss\", \"value\": 0.6691542267799377}, {\"epoch\": 9, \"type\": \"loss\", \"value\": 0.6655324101448059}, {\"epoch\": 10, \"type\": \"loss\", \"value\": 0.6626269221305847}, {\"epoch\": 11, \"type\": \"loss\", \"value\": 0.6589822173118591}, {\"epoch\": 12, \"type\": \"loss\", \"value\": 0.6551512479782104}, {\"epoch\": 13, \"type\": \"loss\", \"value\": 0.6511151194572449}, {\"epoch\": 14, \"type\": \"loss\", \"value\": 0.6469347476959229}, {\"epoch\": 15, \"type\": \"loss\", \"value\": 0.6436874866485596}, {\"epoch\": 16, \"type\": \"loss\", \"value\": 0.6389536261558533}, {\"epoch\": 17, \"type\": \"loss\", \"value\": 0.6345575451850891}, {\"epoch\": 18, \"type\": \"loss\", \"value\": 0.6298846006393433}, {\"epoch\": 19, \"type\": \"loss\", \"value\": 0.6261903643608093}, {\"epoch\": 0, \"type\": \"val_loss\", \"value\": 0.6942797303199768}, {\"epoch\": 1, \"type\": \"val_loss\", \"value\": 0.6902843713760376}, {\"epoch\": 2, \"type\": \"val_loss\", \"value\": 0.6868678331375122}, {\"epoch\": 3, \"type\": \"val_loss\", \"value\": 0.6834937930107117}, {\"epoch\": 4, \"type\": \"val_loss\", \"value\": 0.6803825497627258}, {\"epoch\": 5, \"type\": \"val_loss\", \"value\": 0.6771332025527954}, {\"epoch\": 6, \"type\": \"val_loss\", \"value\": 0.674229621887207}, {\"epoch\": 7, \"type\": \"val_loss\", \"value\": 0.6710131168365479}, {\"epoch\": 8, \"type\": \"val_loss\", \"value\": 0.6678482294082642}, {\"epoch\": 9, \"type\": \"val_loss\", \"value\": 0.6644706130027771}, {\"epoch\": 10, \"type\": \"val_loss\", \"value\": 0.6610152721405029}, {\"epoch\": 11, \"type\": \"val_loss\", \"value\": 0.6574632525444031}, {\"epoch\": 12, \"type\": \"val_loss\", \"value\": 0.6536816358566284}, {\"epoch\": 13, \"type\": \"val_loss\", \"value\": 0.6494783163070679}, {\"epoch\": 14, \"type\": \"val_loss\", \"value\": 0.6454285979270935}, {\"epoch\": 15, \"type\": \"val_loss\", \"value\": 0.6415889859199524}, {\"epoch\": 16, \"type\": \"val_loss\", \"value\": 0.6372033357620239}, {\"epoch\": 17, \"type\": \"val_loss\", \"value\": 0.6326678395271301}, {\"epoch\": 18, \"type\": \"val_loss\", \"value\": 0.6281352043151855}, {\"epoch\": 19, \"type\": \"val_loss\", \"value\": 0.6240695714950562}], \"data-abeb2bbeb4fb61c3231fcf6349550c85\": [{\"epoch\": 0, \"type\": \"precision\", \"value\": 0.44185134768486023}, {\"epoch\": 1, \"type\": \"precision\", \"value\": 0.5096547603607178}, {\"epoch\": 2, \"type\": \"precision\", \"value\": 0.5528758764266968}, {\"epoch\": 3, \"type\": \"precision\", \"value\": 0.5835258960723877}, {\"epoch\": 4, \"type\": \"precision\", \"value\": 0.6069039702415466}, {\"epoch\": 5, \"type\": \"precision\", \"value\": 0.6214165091514587}, {\"epoch\": 6, \"type\": \"precision\", \"value\": 0.6352031230926514}, {\"epoch\": 7, \"type\": \"precision\", \"value\": 0.6385572552680969}, {\"epoch\": 8, \"type\": \"precision\", \"value\": 0.6435630917549133}, {\"epoch\": 9, \"type\": \"precision\", \"value\": 0.6455630660057068}, {\"epoch\": 10, \"type\": \"precision\", \"value\": 0.6491064429283142}, {\"epoch\": 11, \"type\": \"precision\", \"value\": 0.6499733328819275}, {\"epoch\": 12, \"type\": \"precision\", \"value\": 0.6539385914802551}, {\"epoch\": 13, \"type\": \"precision\", \"value\": 0.6515688300132751}, {\"epoch\": 14, \"type\": \"precision\", \"value\": 0.6580191850662231}, {\"epoch\": 15, \"type\": \"precision\", \"value\": 0.6553100943565369}, {\"epoch\": 16, \"type\": \"precision\", \"value\": 0.6595266461372375}, {\"epoch\": 17, \"type\": \"precision\", \"value\": 0.6576897501945496}, {\"epoch\": 18, \"type\": \"precision\", \"value\": 0.6578012108802795}, {\"epoch\": 19, \"type\": \"precision\", \"value\": 0.6600499749183655}, {\"epoch\": 0, \"type\": \"val_precision\", \"value\": 0.4782344102859497}, {\"epoch\": 1, \"type\": \"val_precision\", \"value\": 0.5311855673789978}, {\"epoch\": 2, \"type\": \"val_precision\", \"value\": 0.5539336800575256}, {\"epoch\": 3, \"type\": \"val_precision\", \"value\": 0.5886882543563843}, {\"epoch\": 4, \"type\": \"val_precision\", \"value\": 0.6119321584701538}, {\"epoch\": 5, \"type\": \"val_precision\", \"value\": 0.6371282935142517}, {\"epoch\": 6, \"type\": \"val_precision\", \"value\": 0.6374303102493286}, {\"epoch\": 7, \"type\": \"val_precision\", \"value\": 0.6498451828956604}, {\"epoch\": 8, \"type\": \"val_precision\", \"value\": 0.6510903239250183}, {\"epoch\": 9, \"type\": \"val_precision\", \"value\": 0.6509285569190979}, {\"epoch\": 10, \"type\": \"val_precision\", \"value\": 0.6524733901023865}, {\"epoch\": 11, \"type\": \"val_precision\", \"value\": 0.6521468758583069}, {\"epoch\": 12, \"type\": \"val_precision\", \"value\": 0.6522550582885742}, {\"epoch\": 13, \"type\": \"val_precision\", \"value\": 0.655372679233551}, {\"epoch\": 14, \"type\": \"val_precision\", \"value\": 0.6552271842956543}, {\"epoch\": 15, \"type\": \"val_precision\", \"value\": 0.6534440517425537}, {\"epoch\": 16, \"type\": \"val_precision\", \"value\": 0.6543363332748413}, {\"epoch\": 17, \"type\": \"val_precision\", \"value\": 0.6547507047653198}, {\"epoch\": 18, \"type\": \"val_precision\", \"value\": 0.6558564305305481}, {\"epoch\": 19, \"type\": \"val_precision\", \"value\": 0.6523967385292053}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualizeHistory(blstm_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441/441 [==============================] - 10s 23ms/step\n",
      "189/189 [==============================] - 4s 23ms/step\n",
      "\n",
      "Classifcation Report of Performance on Training data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.62      0.66      7000\n",
      "           1       0.66      0.74      0.70      7109\n",
      "\n",
      "    accuracy                           0.68     14109\n",
      "   macro avg       0.68      0.68      0.68     14109\n",
      "weighted avg       0.68      0.68      0.68     14109\n",
      "\n",
      "\n",
      "\n",
      "* * * * * * * * * * \n",
      "\n",
      "Classifcation Report of Performance on Validation data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.62      0.66      3078\n",
      "           1       0.65      0.74      0.69      2969\n",
      "\n",
      "    accuracy                           0.68      6047\n",
      "   macro avg       0.68      0.68      0.68      6047\n",
      "weighted avg       0.68      0.68      0.68      6047\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performanceReport(blstm, [X_train_enc, X_train_token], y_train, [X_val_enc, X_val_token], y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_ = Conv1D(filters=128, kernel_size=5, activation='relu')(emb)\n",
    "cnn_maxpool = MaxPooling1D(pool_size=5)(cnn_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_flatten_text = Flatten()(cnn_)\n",
    "\n",
    "cnn_combined = Concatenate()([cnn_flatten_text, cat])\n",
    "cnn_flatten = Flatten()(cnn_maxpool)\n",
    "cnn_dense1 = Dense(128, activation=\"relu\")(cnn_flatten)\n",
    "cnn_drop = Dropout(0.3)(cnn_dense1)\n",
    "cnn_output = Dense(1, activation=\"sigmoid\")(cnn_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text_input (InputLayer)        [(None, 57)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 57, 300)      900000      ['text_input[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 53, 128)      192128      ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 10, 128)      0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 1280)         0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 128)          163968      ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 128)          0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " categorical_input (InputLayer)  [(None, 20)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 1)            129         ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,256,225\n",
      "Trainable params: 356,225\n",
      "Non-trainable params: 900,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn = Model(inputs=[categorical_input, text_input], outputs=cnn_output)\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer=\"sgd\", loss=\"binary_crossentropy\", metrics=[keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "111/111 [==============================] - 3s 27ms/step - loss: 0.6915 - precision_3: 0.5268 - val_loss: 0.6888 - val_precision_3: 0.5225\n",
      "Epoch 2/20\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 0.6855 - precision_3: 0.5504 - val_loss: 0.6855 - val_precision_3: 0.5565\n",
      "Epoch 3/20\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 0.6824 - precision_3: 0.5754 - val_loss: 0.6833 - val_precision_3: 0.5570\n",
      "Epoch 4/20\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 0.6798 - precision_3: 0.5807 - val_loss: 0.6811 - val_precision_3: 0.5641\n",
      "Epoch 5/20\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 0.6780 - precision_3: 0.5902 - val_loss: 0.6799 - val_precision_3: 0.5619\n",
      "Epoch 6/20\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 0.6767 - precision_3: 0.5891 - val_loss: 0.6789 - val_precision_3: 0.5605\n",
      "Epoch 7/20\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 0.6752 - precision_3: 0.5877 - val_loss: 0.6776 - val_precision_3: 0.5619\n",
      "Epoch 8/20\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 0.6743 - precision_3: 0.5872 - val_loss: 0.6766 - val_precision_3: 0.5624\n",
      "Epoch 9/20\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 0.6740 - precision_3: 0.5881 - val_loss: 0.6751 - val_precision_3: 0.5653\n",
      "Epoch 10/20\n",
      "111/111 [==============================] - 3s 28ms/step - loss: 0.6715 - precision_3: 0.5916 - val_loss: 0.6741 - val_precision_3: 0.5638\n",
      "Epoch 11/20\n",
      "111/111 [==============================] - 3s 27ms/step - loss: 0.6703 - precision_3: 0.5928 - val_loss: 0.6726 - val_precision_3: 0.5678\n",
      "Epoch 12/20\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 0.6693 - precision_3: 0.5955 - val_loss: 0.6717 - val_precision_3: 0.5678\n",
      "Epoch 13/20\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 0.6676 - precision_3: 0.5938 - val_loss: 0.6700 - val_precision_3: 0.5705\n",
      "Epoch 14/20\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 0.6656 - precision_3: 0.5977 - val_loss: 0.6685 - val_precision_3: 0.5725\n",
      "Epoch 15/20\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 0.6641 - precision_3: 0.6009 - val_loss: 0.6670 - val_precision_3: 0.5740\n",
      "Epoch 16/20\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 0.6628 - precision_3: 0.6001 - val_loss: 0.6652 - val_precision_3: 0.5778\n",
      "Epoch 17/20\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 0.6606 - precision_3: 0.6054 - val_loss: 0.6634 - val_precision_3: 0.5815\n",
      "Epoch 18/20\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 0.6595 - precision_3: 0.6077 - val_loss: 0.6612 - val_precision_3: 0.5855\n",
      "Epoch 19/20\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 0.6567 - precision_3: 0.6100 - val_loss: 0.6589 - val_precision_3: 0.5878\n",
      "Epoch 20/20\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 0.6555 - precision_3: 0.6142 - val_loss: 0.6570 - val_precision_3: 0.5913\n"
     ]
    }
   ],
   "source": [
    "cnn_hist = cnn.fit([X_train_enc, X_train_token], y_train, batch_size=128, epochs=20, validation_data=([X_val_enc, X_val_token], y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-c24a5ec2d7204647be40242acd86ede1.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-c24a5ec2d7204647be40242acd86ede1.vega-embed details,\n",
       "  #altair-viz-c24a5ec2d7204647be40242acd86ede1.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-c24a5ec2d7204647be40242acd86ede1\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-c24a5ec2d7204647be40242acd86ede1\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-c24a5ec2d7204647be40242acd86ede1\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"hconcat\": [{\"data\": {\"name\": \"data-8bda1323e889b13aded7e8869f72b975\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"type\", \"legend\": {\"orient\": \"right\"}, \"type\": \"nominal\"}, \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"scale\": {\"domain\": [0.6555471420288086, 0.6915315985679626]}, \"type\": \"quantitative\"}}, \"title\": \"Training and Validation Loss over epochs\"}, {\"data\": {\"name\": \"data-717040441bb63e231c4fd9126bba4d20\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"type\", \"legend\": {\"orient\": \"right\"}, \"type\": \"nominal\"}, \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"scale\": {\"domain\": [0.5225123763084412, 0.6141612529754639]}, \"type\": \"quantitative\"}}, \"title\": \"Training and Validation Precision over epochs\"}], \"resolve\": {\"scale\": {\"color\": \"independent\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-8bda1323e889b13aded7e8869f72b975\": [{\"epoch\": 0, \"type\": \"loss\", \"value\": 0.6915315985679626}, {\"epoch\": 1, \"type\": \"loss\", \"value\": 0.6854742765426636}, {\"epoch\": 2, \"type\": \"loss\", \"value\": 0.6823793053627014}, {\"epoch\": 3, \"type\": \"loss\", \"value\": 0.6798145771026611}, {\"epoch\": 4, \"type\": \"loss\", \"value\": 0.6780275106430054}, {\"epoch\": 5, \"type\": \"loss\", \"value\": 0.6766675114631653}, {\"epoch\": 6, \"type\": \"loss\", \"value\": 0.6751672625541687}, {\"epoch\": 7, \"type\": \"loss\", \"value\": 0.6743080019950867}, {\"epoch\": 8, \"type\": \"loss\", \"value\": 0.6740064024925232}, {\"epoch\": 9, \"type\": \"loss\", \"value\": 0.6714797019958496}, {\"epoch\": 10, \"type\": \"loss\", \"value\": 0.6702567934989929}, {\"epoch\": 11, \"type\": \"loss\", \"value\": 0.6692671775817871}, {\"epoch\": 12, \"type\": \"loss\", \"value\": 0.6675790548324585}, {\"epoch\": 13, \"type\": \"loss\", \"value\": 0.6656160354614258}, {\"epoch\": 14, \"type\": \"loss\", \"value\": 0.6641190052032471}, {\"epoch\": 15, \"type\": \"loss\", \"value\": 0.6627905964851379}, {\"epoch\": 16, \"type\": \"loss\", \"value\": 0.6605666875839233}, {\"epoch\": 17, \"type\": \"loss\", \"value\": 0.6595311760902405}, {\"epoch\": 18, \"type\": \"loss\", \"value\": 0.656747043132782}, {\"epoch\": 19, \"type\": \"loss\", \"value\": 0.6555471420288086}, {\"epoch\": 0, \"type\": \"val_loss\", \"value\": 0.6887720823287964}, {\"epoch\": 1, \"type\": \"val_loss\", \"value\": 0.6855064034461975}, {\"epoch\": 2, \"type\": \"val_loss\", \"value\": 0.6832771897315979}, {\"epoch\": 3, \"type\": \"val_loss\", \"value\": 0.6811395883560181}, {\"epoch\": 4, \"type\": \"val_loss\", \"value\": 0.6798853278160095}, {\"epoch\": 5, \"type\": \"val_loss\", \"value\": 0.6788559556007385}, {\"epoch\": 6, \"type\": \"val_loss\", \"value\": 0.6776012182235718}, {\"epoch\": 7, \"type\": \"val_loss\", \"value\": 0.6765995621681213}, {\"epoch\": 8, \"type\": \"val_loss\", \"value\": 0.6751259565353394}, {\"epoch\": 9, \"type\": \"val_loss\", \"value\": 0.6740821599960327}, {\"epoch\": 10, \"type\": \"val_loss\", \"value\": 0.6725642681121826}, {\"epoch\": 11, \"type\": \"val_loss\", \"value\": 0.6717135906219482}, {\"epoch\": 12, \"type\": \"val_loss\", \"value\": 0.6699869632720947}, {\"epoch\": 13, \"type\": \"val_loss\", \"value\": 0.6684679985046387}, {\"epoch\": 14, \"type\": \"val_loss\", \"value\": 0.6669520735740662}, {\"epoch\": 15, \"type\": \"val_loss\", \"value\": 0.6652074456214905}, {\"epoch\": 16, \"type\": \"val_loss\", \"value\": 0.6633960604667664}, {\"epoch\": 17, \"type\": \"val_loss\", \"value\": 0.6612266302108765}, {\"epoch\": 18, \"type\": \"val_loss\", \"value\": 0.6589227914810181}, {\"epoch\": 19, \"type\": \"val_loss\", \"value\": 0.6569938659667969}], \"data-717040441bb63e231c4fd9126bba4d20\": [{\"epoch\": 0, \"type\": \"precision\", \"value\": 0.5267768502235413}, {\"epoch\": 1, \"type\": \"precision\", \"value\": 0.5504016280174255}, {\"epoch\": 2, \"type\": \"precision\", \"value\": 0.5753743052482605}, {\"epoch\": 3, \"type\": \"precision\", \"value\": 0.5807445049285889}, {\"epoch\": 4, \"type\": \"precision\", \"value\": 0.5901873707771301}, {\"epoch\": 5, \"type\": \"precision\", \"value\": 0.5891373157501221}, {\"epoch\": 6, \"type\": \"precision\", \"value\": 0.587681770324707}, {\"epoch\": 7, \"type\": \"precision\", \"value\": 0.5871585607528687}, {\"epoch\": 8, \"type\": \"precision\", \"value\": 0.5880547165870667}, {\"epoch\": 9, \"type\": \"precision\", \"value\": 0.5916289687156677}, {\"epoch\": 10, \"type\": \"precision\", \"value\": 0.5928093791007996}, {\"epoch\": 11, \"type\": \"precision\", \"value\": 0.5955313444137573}, {\"epoch\": 12, \"type\": \"precision\", \"value\": 0.5938228964805603}, {\"epoch\": 13, \"type\": \"precision\", \"value\": 0.5977269411087036}, {\"epoch\": 14, \"type\": \"precision\", \"value\": 0.6008943319320679}, {\"epoch\": 15, \"type\": \"precision\", \"value\": 0.6000834107398987}, {\"epoch\": 16, \"type\": \"precision\", \"value\": 0.6053618788719177}, {\"epoch\": 17, \"type\": \"precision\", \"value\": 0.6077355742454529}, {\"epoch\": 18, \"type\": \"precision\", \"value\": 0.6100327968597412}, {\"epoch\": 19, \"type\": \"precision\", \"value\": 0.6141612529754639}, {\"epoch\": 0, \"type\": \"val_precision\", \"value\": 0.5225123763084412}, {\"epoch\": 1, \"type\": \"val_precision\", \"value\": 0.5565449595451355}, {\"epoch\": 2, \"type\": \"val_precision\", \"value\": 0.5569892525672913}, {\"epoch\": 3, \"type\": \"val_precision\", \"value\": 0.5641279220581055}, {\"epoch\": 4, \"type\": \"val_precision\", \"value\": 0.5618955492973328}, {\"epoch\": 5, \"type\": \"val_precision\", \"value\": 0.5605095624923706}, {\"epoch\": 6, \"type\": \"val_precision\", \"value\": 0.561855673789978}, {\"epoch\": 7, \"type\": \"val_precision\", \"value\": 0.5624207854270935}, {\"epoch\": 8, \"type\": \"val_precision\", \"value\": 0.5653027892112732}, {\"epoch\": 9, \"type\": \"val_precision\", \"value\": 0.5638468861579895}, {\"epoch\": 10, \"type\": \"val_precision\", \"value\": 0.5677546858787537}, {\"epoch\": 11, \"type\": \"val_precision\", \"value\": 0.5678470730781555}, {\"epoch\": 12, \"type\": \"val_precision\", \"value\": 0.5705087184906006}, {\"epoch\": 13, \"type\": \"val_precision\", \"value\": 0.5724823474884033}, {\"epoch\": 14, \"type\": \"val_precision\", \"value\": 0.5739852786064148}, {\"epoch\": 15, \"type\": \"val_precision\", \"value\": 0.5777634978294373}, {\"epoch\": 16, \"type\": \"val_precision\", \"value\": 0.5814838409423828}, {\"epoch\": 17, \"type\": \"val_precision\", \"value\": 0.5854922533035278}, {\"epoch\": 18, \"type\": \"val_precision\", \"value\": 0.5877937078475952}, {\"epoch\": 19, \"type\": \"val_precision\", \"value\": 0.5913178324699402}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualizeHistory(cnn_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441/441 [==============================] - 1s 3ms/step\n",
      "189/189 [==============================] - 1s 3ms/step\n",
      "\n",
      "Classifcation Report of Performance on Training data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.59      0.60      7000\n",
      "           1       0.61      0.64      0.63      7109\n",
      "\n",
      "    accuracy                           0.62     14109\n",
      "   macro avg       0.62      0.62      0.62     14109\n",
      "weighted avg       0.62      0.62      0.62     14109\n",
      "\n",
      "\n",
      "\n",
      "* * * * * * * * * * \n",
      "\n",
      "Classifcation Report of Performance on Validation data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.57      0.60      3078\n",
      "           1       0.59      0.64      0.62      2969\n",
      "\n",
      "    accuracy                           0.61      6047\n",
      "   macro avg       0.61      0.61      0.61      6047\n",
      "weighted avg       0.61      0.61      0.61      6047\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performanceReport(cnn, [X_train_enc, X_train_token], y_train, [X_val_enc, X_val_token], y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsmml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
