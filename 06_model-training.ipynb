{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Fake News Detection\n",
    "\n",
    "By Felix Daubner - Hochschule der Medien\n",
    "\n",
    "Module 'Supervised and Unsupervised Learning' - Prof. Dr.-Ing. Johannes Maucher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To-Do:\n",
    "- Prepare data for training and validation\n",
    "- Define model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection\n",
    "- nur Text\n",
    "- nur Kategorien (Channel, Person, etc.)\n",
    "- alles\n",
    "\n",
    "Performance vergleichen\n",
    "\n",
    "- CNN?\n",
    "- Neuronales Netz (MLP)\n",
    "- LSTM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section contains the model training and feature selection. Different types of models should be trained and then compared to find out which model fits the challenge, to determine whether a political statement was fake-news or true, best. There are three types of models to be compared: MLP, CNN and LSTM. Those models should also vary in terms of hyperparameters like layers, neurons, optimization and else. The best model is evaluated and then optimized in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare and save data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/processed.csv\", sep=\";\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting defining the different models, the data is prepared for the training process. The neural network to be trained only takes numpy arrays as input. Thus, the data currently saved as a pandas DataFrame is converted in to a numpy array. In this conversion process, only \"token\", the encoded channel and issue columns and \"truth\" are kept meaning column 'statement' is dropped as it can not be used for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data.drop([\"statement\"], axis=1).apply(np.array))\n",
    "y = np.array(data[\"truth\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prepared data 'X' containing all the features and 'y' containing all targets to the corresponding features. Both arrays are saved as a csv-file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"data/X.csv\", X, delimiter=\";\")\n",
    "np.savetxt(\"data/y.csv\", y, delimiter=\";\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsmml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
