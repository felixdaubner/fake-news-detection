{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Fake News Detection\n",
    "\n",
    "By Felix Daubner - Hochschule der Medien\n",
    "\n",
    "Module 'Supervised and Unsupervised Learning' - Prof. Dr.-Ing. Johannes Maucher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, Flatten, Dense, LSTM, Conv1D, Flatten, MaxPooling1D, Dropout, Bidirectional, Input, Concatenate\n",
    "import pickle\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "NUM_WORDS=3000\n",
    "MAX_SEQUENCE_LEN = 57\n",
    "NUM_CAT = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareFeatures(X):\n",
    "    X_token = np.array(X[\"token\"].apply(np.asarray))\n",
    "    X_token = np.array([arr for arr in X_token])\n",
    "\n",
    "    X_enc = np.array(X.drop([\"token\"], axis=1).apply(np.array))\n",
    "\n",
    "    return X_token, X_enc\n",
    "\n",
    "def prepareTarget(y):\n",
    "    return np.array(y)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section contains the model training and feature selection. Different types of models should be trained and then compared to find out which model fits the challenge, to determine whether a political statement was fake-news or true, best. There are three types of models to be compared: MLP, CNN and LSTM. Those models should also vary in terms of hyperparameters like layers, neurons, optimization and else. The best model is evaluated and then optimized in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"data/processed.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['statement', 'channel_Instagram', 'channel_Other', 'channel_TV',\n",
       "       'channel_TikTok', 'channel_X', 'channel_ad', 'channel_article',\n",
       "       'channel_blog', 'channel_campaign', 'channel_debate',\n",
       "       'channel_interview', 'channel_lecture', 'channel_mail',\n",
       "       'channel_podcast', 'channel_presentation', 'channel_press',\n",
       "       'channel_social media', 'channel_speech', 'channel_talk',\n",
       "       'channel_video', 'truth', 'token', 'statement_stop', 'token_stop'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting defining the different models, the data is prepared for the training process. The neural network to be trained only takes numpy arrays as input. Thus, the data currently saved as a pandas DataFrame is converted in to a numpy array. In this conversion process, only \"token\", the encoded channel and issue columns and \"truth\" are kept meaning column 'statement' is dropped as it can not be used for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After splitting the data into features and target, the features still have to preprared for training by splitting the encoded categorical data from the tokenized and padded statements. The statement data has to be taken care of using an Embedding Layer while a Dense layer is sufficient to handle the encoded categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop([\"statement\", \"statement_stop\", \"token_stop\", \"truth\"], axis=1)\n",
    "y = data[\"truth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_token, X_train_enc = prepareFeatures(X_train)\n",
    "X_val_token, X_val_enc = prepareFeatures(X_val)\n",
    "y_train = prepareTarget(y_train)\n",
    "y_val = prepareTarget(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_json(\"data/LIAR_processed.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop([\"statement\", \"statement_stop\", \"token_stop\", \"truth\"], axis=1)\n",
    "y_test = test[\"truth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_token, X_test_enc = prepareFeatures(X_test)\n",
    "y_test = prepareTarget(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at fake-news detection, it is decided which of accuracy, precision or recall should be optimized. Most often, accuracy is not a good metric as it doesn't include the cost of mis-predicting. That's why either precision or recall should be used.\n",
    "The worst case at fake-news is when a fake-news is not identified as fake-news. Whereas the other way, a true statement being classified as fake-news does not harm in the same way. Translating this into the terms of this project means a false positive (\"a statement which is 'fake' (0) gets classified as 'true' (1)\") is worse than a false negative (\"a statement which is 'true' (1) gets classified as 'false' (0)\"). The metrics focusing on optimizing the false positives is precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, four different types models are trained and evaluated. Based on those evaluations, the best model is chosen and optimized until pre-defined metrics reach their peak. The evaluation for the best model are done using all available features of the data. In the following section [Optimiziation](07_evaluation-optimization.ipynb) the most useful features and hyperparameters of the model are chosen until the best model is reached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = KeyedVectors.load_word2vec_format(\"wiki-news-300d-1M.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tokenizer/tokenizer.pickle\", \"rb\") as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300  \n",
    "word_index = tokenizer.word_index \n",
    "num_words = min(len(word_index) + 1, NUM_WORDS)  \n",
    "\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i < num_words:\n",
    "        if word in word2vec.key_to_index:\n",
    "            embedding_vector = word2vec[word]\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = Input(shape=(MAX_SEQUENCE_LEN,), name=\"text_input\")\n",
    "categorical_input = Input(shape=(NUM_CAT,), name=\"categorical_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = Embedding(NUM_WORDS, embedding_dim, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LEN, trainable=False)(text_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Dense(32, activation=\"relu\")(categorical_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedforward Neural Nerwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_flatten_text = Flatten()(emb)\n",
    "\n",
    "ff_combined = Concatenate()([ff_flatten_text, cat])\n",
    "ff_dense1 = Dense(128, activation=\"relu\")(ff_combined)\n",
    "ff_dense2 = Dense(64, activation=\"relu\")(ff_dense1)\n",
    "ff_output = Dense(1, activation=\"sigmoid\")(ff_dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text_input (InputLayer)        [(None, 57)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)        (None, 57, 300)      900000      ['text_input[0][0]']             \n",
      "                                                                                                  \n",
      " categorical_input (InputLayer)  [(None, 20)]        0           []                               \n",
      "                                                                                                  \n",
      " flatten_9 (Flatten)            (None, 17100)        0           ['embedding_4[0][0]']            \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 32)           672         ['categorical_input[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_13 (Concatenate)   (None, 17132)        0           ['flatten_9[0][0]',              \n",
      "                                                                  'dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " dense_32 (Dense)               (None, 128)          2193024     ['concatenate_13[0][0]']         \n",
      "                                                                                                  \n",
      " dense_33 (Dense)               (None, 64)           8256        ['dense_32[0][0]']               \n",
      "                                                                                                  \n",
      " dense_34 (Dense)               (None, 1)            65          ['dense_33[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,102,017\n",
      "Trainable params: 2,202,017\n",
      "Non-trainable params: 900,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ff = Model(inputs=[categorical_input, text_input], outputs=ff_output)\n",
    "ff.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "111/111 [==============================] - 2s 11ms/step - loss: 0.5448 - precision_5: 0.7067 - val_loss: 0.4498 - val_precision_5: 0.7915\n",
      "Epoch 2/20\n",
      "111/111 [==============================] - 1s 11ms/step - loss: 0.3195 - precision_5: 0.8558 - val_loss: 0.3925 - val_precision_5: 0.8134\n",
      "Epoch 3/20\n",
      "111/111 [==============================] - 1s 11ms/step - loss: 0.1451 - precision_5: 0.9457 - val_loss: 0.3793 - val_precision_5: 0.8655\n",
      "Epoch 4/20\n",
      "111/111 [==============================] - 1s 11ms/step - loss: 0.0523 - precision_5: 0.9869 - val_loss: 0.4322 - val_precision_5: 0.8519\n",
      "Epoch 5/20\n",
      "111/111 [==============================] - 1s 11ms/step - loss: 0.0139 - precision_5: 0.9985 - val_loss: 0.5355 - val_precision_5: 0.8672\n",
      "Epoch 6/20\n",
      "111/111 [==============================] - 1s 11ms/step - loss: 0.0033 - precision_5: 0.9999 - val_loss: 0.6107 - val_precision_5: 0.8511\n",
      "Epoch 7/20\n",
      "111/111 [==============================] - 1s 11ms/step - loss: 0.0016 - precision_5: 0.9999 - val_loss: 0.6439 - val_precision_5: 0.8507\n",
      "Epoch 8/20\n",
      "111/111 [==============================] - 1s 11ms/step - loss: 8.6288e-04 - precision_5: 1.0000 - val_loss: 0.6688 - val_precision_5: 0.8470\n",
      "Epoch 9/20\n",
      "111/111 [==============================] - 1s 11ms/step - loss: 0.0011 - precision_5: 0.9999 - val_loss: 0.6852 - val_precision_5: 0.8482\n",
      "Epoch 10/20\n",
      "111/111 [==============================] - 1s 11ms/step - loss: 5.8259e-04 - precision_5: 1.0000 - val_loss: 0.6957 - val_precision_5: 0.8509\n",
      "Epoch 11/20\n",
      "111/111 [==============================] - 1s 11ms/step - loss: 5.4107e-04 - precision_5: 0.9999 - val_loss: 0.7213 - val_precision_5: 0.8455\n",
      "Epoch 12/20\n",
      "111/111 [==============================] - 1s 11ms/step - loss: 3.5775e-04 - precision_5: 1.0000 - val_loss: 0.7362 - val_precision_5: 0.8465\n",
      "Epoch 13/20\n",
      "111/111 [==============================] - 1s 12ms/step - loss: 1.9937e-04 - precision_5: 1.0000 - val_loss: 0.7466 - val_precision_5: 0.8489\n",
      "Epoch 14/20\n",
      "111/111 [==============================] - 1s 12ms/step - loss: 1.6414e-04 - precision_5: 1.0000 - val_loss: 0.7614 - val_precision_5: 0.8468\n",
      "Epoch 15/20\n",
      "111/111 [==============================] - 1s 11ms/step - loss: 1.3876e-04 - precision_5: 1.0000 - val_loss: 0.7699 - val_precision_5: 0.8489\n",
      "Epoch 16/20\n",
      "111/111 [==============================] - 1s 11ms/step - loss: 1.1894e-04 - precision_5: 1.0000 - val_loss: 0.7773 - val_precision_5: 0.8507\n",
      "Epoch 17/20\n",
      "111/111 [==============================] - 1s 11ms/step - loss: 1.0301e-04 - precision_5: 1.0000 - val_loss: 0.7865 - val_precision_5: 0.8509\n",
      "Epoch 18/20\n",
      "111/111 [==============================] - 1s 11ms/step - loss: 8.9864e-05 - precision_5: 1.0000 - val_loss: 0.8014 - val_precision_5: 0.8466\n",
      "Epoch 19/20\n",
      "111/111 [==============================] - 1s 11ms/step - loss: 7.8979e-05 - precision_5: 1.0000 - val_loss: 0.8075 - val_precision_5: 0.8476\n",
      "Epoch 20/20\n",
      "111/111 [==============================] - 1s 11ms/step - loss: 6.9801e-05 - precision_5: 1.0000 - val_loss: 0.8144 - val_precision_5: 0.8480\n"
     ]
    }
   ],
   "source": [
    "ff_history = ff.fit([X_train_enc, X_train_token], y_train, epochs=20, batch_size=128, validation_data=([X_val_enc, X_val_token], y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_ = LSTM(64)(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_combined = Concatenate()([lstm_, cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_dense1 = Dense(64, activation='relu')(lstm_combined)\n",
    "lstm_drop1 = Dropout(0.2)(lstm_dense1)\n",
    "lstm_dense2 = Dense(32, activation='relu')(lstm_drop1)\n",
    "lstm_drop2 = Dropout(0.4)(lstm_dense2)\n",
    "lstm_output = Dense(1, activation='sigmoid')(lstm_drop2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text_input (InputLayer)        [(None, 57)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)        (None, 57, 300)      900000      ['text_input[0][0]']             \n",
      "                                                                                                  \n",
      " categorical_input (InputLayer)  [(None, 20)]        0           []                               \n",
      "                                                                                                  \n",
      " lstm_7 (LSTM)                  (None, 64)           93440       ['embedding_4[0][0]']            \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 32)           672         ['categorical_input[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_14 (Concatenate)   (None, 96)           0           ['lstm_7[0][0]',                 \n",
      "                                                                  'dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " dense_35 (Dense)               (None, 64)           6208        ['concatenate_14[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 64)           0           ['dense_35[0][0]']               \n",
      "                                                                                                  \n",
      " dense_36 (Dense)               (None, 32)           2080        ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 32)           0           ['dense_36[0][0]']               \n",
      "                                                                                                  \n",
      " dense_37 (Dense)               (None, 1)            33          ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,002,433\n",
      "Trainable params: 102,433\n",
      "Non-trainable params: 900,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = Model(inputs=[categorical_input, text_input], outputs=lstm_output)\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "111/111 [==============================] - 8s 57ms/step - loss: 0.6170 - precision_6: 0.6387 - val_loss: 0.5513 - val_precision_6: 0.6711\n",
      "Epoch 2/20\n",
      "111/111 [==============================] - 6s 53ms/step - loss: 0.5518 - precision_6: 0.6866 - val_loss: 0.5379 - val_precision_6: 0.6642\n",
      "Epoch 3/20\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.5312 - precision_6: 0.7037 - val_loss: 0.5256 - val_precision_6: 0.6939\n",
      "Epoch 4/20\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.5156 - precision_6: 0.7181 - val_loss: 0.5209 - val_precision_6: 0.6883\n",
      "Epoch 5/20\n",
      "111/111 [==============================] - 6s 53ms/step - loss: 0.4935 - precision_6: 0.7262 - val_loss: 0.5188 - val_precision_6: 0.6686\n",
      "Epoch 6/20\n",
      "111/111 [==============================] - 6s 54ms/step - loss: 0.4711 - precision_6: 0.7387 - val_loss: 0.4976 - val_precision_6: 0.7174\n",
      "Epoch 7/20\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.4475 - precision_6: 0.7550 - val_loss: 0.4929 - val_precision_6: 0.7093\n",
      "Epoch 8/20\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.4165 - precision_6: 0.7769 - val_loss: 0.4838 - val_precision_6: 0.7189\n",
      "Epoch 9/20\n",
      "111/111 [==============================] - 6s 52ms/step - loss: 0.3825 - precision_6: 0.7959 - val_loss: 0.5011 - val_precision_6: 0.7753\n",
      "Epoch 10/20\n",
      "111/111 [==============================] - 6s 52ms/step - loss: 0.3510 - precision_6: 0.8178 - val_loss: 0.4644 - val_precision_6: 0.7661\n",
      "Epoch 11/20\n",
      "111/111 [==============================] - 6s 53ms/step - loss: 0.3161 - precision_6: 0.8393 - val_loss: 0.4699 - val_precision_6: 0.7673\n",
      "Epoch 12/20\n",
      "111/111 [==============================] - 6s 54ms/step - loss: 0.2938 - precision_6: 0.8526 - val_loss: 0.4909 - val_precision_6: 0.8080\n",
      "Epoch 13/20\n",
      "111/111 [==============================] - 6s 58ms/step - loss: 0.2530 - precision_6: 0.8755 - val_loss: 0.4833 - val_precision_6: 0.7671\n",
      "Epoch 14/20\n",
      "111/111 [==============================] - 6s 53ms/step - loss: 0.2260 - precision_6: 0.8911 - val_loss: 0.4830 - val_precision_6: 0.8150\n",
      "Epoch 15/20\n",
      "111/111 [==============================] - 6s 54ms/step - loss: 0.1991 - precision_6: 0.9056 - val_loss: 0.4787 - val_precision_6: 0.8117\n",
      "Epoch 16/20\n",
      "111/111 [==============================] - 6s 54ms/step - loss: 0.1765 - precision_6: 0.9192 - val_loss: 0.5382 - val_precision_6: 0.7883\n",
      "Epoch 17/20\n",
      "111/111 [==============================] - 7s 59ms/step - loss: 0.1546 - precision_6: 0.9292 - val_loss: 0.5719 - val_precision_6: 0.8357\n",
      "Epoch 18/20\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.1301 - precision_6: 0.9448 - val_loss: 0.5510 - val_precision_6: 0.8107\n",
      "Epoch 19/20\n",
      "111/111 [==============================] - 6s 54ms/step - loss: 0.1169 - precision_6: 0.9489 - val_loss: 0.5711 - val_precision_6: 0.8369\n",
      "Epoch 20/20\n",
      "111/111 [==============================] - 6s 54ms/step - loss: 0.0985 - precision_6: 0.9609 - val_loss: 0.6087 - val_precision_6: 0.8469\n"
     ]
    }
   ],
   "source": [
    "lstm_hist = lstm.fit([X_train_enc, X_train_token], y_train, batch_size=128, epochs=20, validation_data=([X_val_enc, X_val_token], y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-directional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "blstm_ = Bidirectional(LSTM(128))(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "blstm_combined = Concatenate()([blstm_, cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "blstm_dense1 = Dense(64, activation='relu')(blstm_combined)\n",
    "blstm_drop1 = Dropout(0.2)(blstm_dense1)\n",
    "blstm_output = Dense(1, activation='sigmoid')(blstm_drop1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text_input (InputLayer)        [(None, 57)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)        (None, 57, 300)      900000      ['text_input[0][0]']             \n",
      "                                                                                                  \n",
      " categorical_input (InputLayer)  [(None, 20)]        0           []                               \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 256)         439296      ['embedding_4[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 32)           672         ['categorical_input[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenate)   (None, 288)          0           ['bidirectional_1[0][0]',        \n",
      "                                                                  'dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " dense_38 (Dense)               (None, 64)           18496       ['concatenate_15[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 64)           0           ['dense_38[0][0]']               \n",
      "                                                                                                  \n",
      " dense_39 (Dense)               (None, 1)            65          ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,358,529\n",
      "Trainable params: 458,529\n",
      "Non-trainable params: 900,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "blstm = Model(inputs=[categorical_input, text_input], outputs=blstm_output)\n",
    "blstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "blstm.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "111/111 [==============================] - 15s 118ms/step - loss: 0.5906 - precision_7: 0.6647 - val_loss: 0.5501 - val_precision_7: 0.6678\n",
      "Epoch 2/20\n",
      "111/111 [==============================] - 14s 130ms/step - loss: 0.5361 - precision_7: 0.7020 - val_loss: 0.5410 - val_precision_7: 0.7326\n",
      "Epoch 3/20\n",
      "111/111 [==============================] - 13s 118ms/step - loss: 0.5197 - precision_7: 0.7123 - val_loss: 0.5254 - val_precision_7: 0.7003\n",
      "Epoch 4/20\n",
      "111/111 [==============================] - 13s 120ms/step - loss: 0.4932 - precision_7: 0.7311 - val_loss: 0.5159 - val_precision_7: 0.6907\n",
      "Epoch 5/20\n",
      "111/111 [==============================] - 13s 119ms/step - loss: 0.4655 - precision_7: 0.7479 - val_loss: 0.5006 - val_precision_7: 0.7011\n",
      "Epoch 6/20\n",
      "111/111 [==============================] - 13s 122ms/step - loss: 0.4282 - precision_7: 0.7650 - val_loss: 0.5428 - val_precision_7: 0.7645\n",
      "Epoch 7/20\n",
      "111/111 [==============================] - 13s 120ms/step - loss: 0.3996 - precision_7: 0.7885 - val_loss: 0.4843 - val_precision_7: 0.7332\n",
      "Epoch 8/20\n",
      "111/111 [==============================] - 13s 122ms/step - loss: 0.3555 - precision_7: 0.8120 - val_loss: 0.4982 - val_precision_7: 0.7729\n",
      "Epoch 9/20\n",
      "111/111 [==============================] - 14s 123ms/step - loss: 0.3233 - precision_7: 0.8366 - val_loss: 0.4902 - val_precision_7: 0.7866\n",
      "Epoch 10/20\n",
      "111/111 [==============================] - 13s 115ms/step - loss: 0.2875 - precision_7: 0.8524 - val_loss: 0.5033 - val_precision_7: 0.7305\n",
      "Epoch 11/20\n",
      "111/111 [==============================] - 14s 124ms/step - loss: 0.2407 - precision_7: 0.8851 - val_loss: 0.4678 - val_precision_7: 0.7943\n",
      "Epoch 12/20\n",
      "111/111 [==============================] - 14s 124ms/step - loss: 0.2045 - precision_7: 0.9050 - val_loss: 0.5038 - val_precision_7: 0.7999\n",
      "Epoch 13/20\n",
      "111/111 [==============================] - 14s 123ms/step - loss: 0.1730 - precision_7: 0.9232 - val_loss: 0.5316 - val_precision_7: 0.8310\n",
      "Epoch 14/20\n",
      "111/111 [==============================] - 13s 117ms/step - loss: 0.1449 - precision_7: 0.9377 - val_loss: 0.5688 - val_precision_7: 0.8227\n",
      "Epoch 15/20\n",
      "111/111 [==============================] - 13s 121ms/step - loss: 0.1122 - precision_7: 0.9547 - val_loss: 0.5733 - val_precision_7: 0.8345\n",
      "Epoch 16/20\n",
      "111/111 [==============================] - 14s 124ms/step - loss: 0.1048 - precision_7: 0.9580 - val_loss: 0.5766 - val_precision_7: 0.8351\n",
      "Epoch 17/20\n",
      "111/111 [==============================] - 13s 118ms/step - loss: 0.0762 - precision_7: 0.9714 - val_loss: 0.6389 - val_precision_7: 0.8510\n",
      "Epoch 18/20\n",
      "111/111 [==============================] - 13s 121ms/step - loss: 0.0620 - precision_7: 0.9764 - val_loss: 0.6856 - val_precision_7: 0.8400\n",
      "Epoch 19/20\n",
      "111/111 [==============================] - 13s 119ms/step - loss: 0.0550 - precision_7: 0.9808 - val_loss: 0.7099 - val_precision_7: 0.8384\n",
      "Epoch 20/20\n",
      "111/111 [==============================] - 13s 119ms/step - loss: 0.0512 - precision_7: 0.9820 - val_loss: 0.7263 - val_precision_7: 0.8328\n"
     ]
    }
   ],
   "source": [
    "blstm_hist = blstm.fit([X_train_enc, X_train_token], y_train, batch_size=128, epochs=20, validation_data=([X_val_enc, X_val_token], y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_ = Conv1D(filters=128, kernel_size=5, activation='relu')(emb)\n",
    "cnn_maxpool = MaxPooling1D(pool_size=5)(cnn_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_flatten_text = Flatten()(cnn_)\n",
    "\n",
    "cnn_combined = Concatenate()([cnn_flatten_text, cat])\n",
    "cnn_flatten = Flatten()(cnn_maxpool)\n",
    "cnn_dense1 = Dense(128, activation=\"relu\")(cnn_flatten)\n",
    "cnn_output = Dense(1, activation=\"sigmoid\")(cnn_dense1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text_input (InputLayer)        [(None, 57)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)        (None, 57, 300)      900000      ['text_input[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 53, 128)      192128      ['embedding_4[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 10, 128)     0           ['conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_18 (Flatten)           (None, 1280)         0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " dense_40 (Dense)               (None, 128)          163968      ['flatten_18[0][0]']             \n",
      "                                                                                                  \n",
      " categorical_input (InputLayer)  [(None, 20)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_41 (Dense)               (None, 1)            129         ['dense_40[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,256,225\n",
      "Trainable params: 356,225\n",
      "Non-trainable params: 900,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn = Model(inputs=[categorical_input, text_input], outputs=cnn_output)\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 0.5922 - precision_8: 0.6826 - val_loss: 0.5114 - val_precision_8: 0.7719\n",
      "Epoch 2/20\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 0.3849 - precision_8: 0.8329 - val_loss: 0.3838 - val_precision_8: 0.8140\n",
      "Epoch 3/20\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 0.1814 - precision_8: 0.9367 - val_loss: 0.4162 - val_precision_8: 0.8091\n",
      "Epoch 4/20\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 0.0749 - precision_8: 0.9808 - val_loss: 0.4114 - val_precision_8: 0.8578\n",
      "Epoch 5/20\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 0.0336 - precision_8: 0.9941 - val_loss: 0.4418 - val_precision_8: 0.8717\n",
      "Epoch 6/20\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 0.0210 - precision_8: 0.9968 - val_loss: 0.4727 - val_precision_8: 0.8696\n",
      "Epoch 7/20\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 0.0154 - precision_8: 0.9980 - val_loss: 0.5408 - val_precision_8: 0.8356\n",
      "Epoch 8/20\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 0.0135 - precision_8: 0.9976 - val_loss: 0.5503 - val_precision_8: 0.8995\n",
      "Epoch 9/20\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 0.0174 - precision_8: 0.9970 - val_loss: 0.6302 - val_precision_8: 0.8366\n",
      "Epoch 10/20\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 0.0144 - precision_8: 0.9972 - val_loss: 0.6103 - val_precision_8: 0.8383\n",
      "Epoch 11/20\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 0.0138 - precision_8: 0.9986 - val_loss: 0.7791 - val_precision_8: 0.7875\n",
      "Epoch 12/20\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 0.0852 - precision_8: 0.9714 - val_loss: 0.6063 - val_precision_8: 0.8832\n",
      "Epoch 13/20\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 0.0446 - precision_8: 0.9846 - val_loss: 0.6575 - val_precision_8: 0.8199\n",
      "Epoch 14/20\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 0.0157 - precision_8: 0.9962 - val_loss: 0.6874 - val_precision_8: 0.8251\n",
      "Epoch 15/20\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 0.0102 - precision_8: 0.9986 - val_loss: 0.7916 - val_precision_8: 0.8002\n",
      "Epoch 16/20\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 0.0079 - precision_8: 0.9990 - val_loss: 0.6853 - val_precision_8: 0.8562\n",
      "Epoch 17/20\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 0.0085 - precision_8: 0.9986 - val_loss: 0.7350 - val_precision_8: 0.8367\n",
      "Epoch 18/20\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 0.0098 - precision_8: 0.9986 - val_loss: 0.7070 - val_precision_8: 0.8793\n",
      "Epoch 19/20\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 0.0063 - precision_8: 0.9987 - val_loss: 0.7278 - val_precision_8: 0.8502\n",
      "Epoch 20/20\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 0.0069 - precision_8: 0.9994 - val_loss: 0.7296 - val_precision_8: 0.8534\n"
     ]
    }
   ],
   "source": [
    "cnn_hist = cnn.fit([X_train_enc, X_train_token], y_train, batch_size=128, epochs=20, validation_data=([X_val_enc, X_val_token], y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsmml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
